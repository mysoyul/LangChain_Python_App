{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1F5lTDp5UPf0",
   "metadata": {
    "id": "1F5lTDp5UPf0"
   },
   "source": [
    "### 1) ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai langchain_community chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI ì¸ì¦í‚¤ ì„¤ì •\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9abc5",
   "metadata": {},
   "source": [
    "##### Chroma ê°„ë‹¨í•œ ì˜ˆì œ\n",
    "* Chroma DBì— í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0430b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI ë¬¸ì„œ ê°œìˆ˜: 6\n",
      "ê¸ˆìœµ ë¬¸ì„œ ê°œìˆ˜: 5\n",
      "Chroma ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ!\n",
      " ì €ì¥ëœ ë²¡í„° ê°œìˆ˜: 11, íƒ€ì… <class 'list'>\n",
      "\n",
      "ğŸ” [Query]: Transformer ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\n",
      "\n",
      "ğŸ”¹ [Result 1]: Token (í† í°)\n",
      "\n",
      "ì •ì˜: í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë” ì‘ì€ ë‹¨ìœ„(ë‹¨ì–´, ë¬¸ì, ë¬¸ì¥ ë“±)ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •.\n",
      "ì˜ˆì‹œ: \"AIëŠ” í˜ì‹ ì ì´ë‹¤\"ë¥¼ [\"AI\", \"ëŠ”\", \"í˜ì‹ ì \", \"ì´ë‹¤\"]ë¡œ ë¶„í• .\n",
      "ì—°ê´€ í‚¤ì›Œë“œ: í† í°í™”, NLP, í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
      "\n",
      "Transformer (íŠ¸ëœìŠ¤í¬ë¨¸)\n",
      "\n",
      "ì •ì˜: ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ë¡œ, ë³‘ë ¬ ì—°ì‚°ê³¼ ì¥ê¸° ì˜ì¡´ì„± ì²˜ë¦¬ê°€ ê°•ì .\n",
      "ì˜ˆì‹œ: GPT, BERT ë“±ì˜ ëª¨ë¸ì´ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•¨.\n",
      "ì—°ê´€ í‚¤ì›Œë“œ: ë”¥ëŸ¬ë‹, ìê¸° ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜, NLP\n",
      "\n",
      "Self-Attention (ìê¸° ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜)\n",
      "\n",
      "ì •ì˜...\n",
      "\n",
      "ğŸ”¹ [Result 2]: Earnings Per Share (ì£¼ë‹¹ìˆœì´ìµ, EPS)\n",
      "\n",
      "ì •ì˜: ê¸°ì—…ì´ ë²Œì–´ë“¤ì¸ ìˆœì´ìµì„ ì´ ë°œí–‰ ì£¼ì‹ ìˆ˜ë¡œ ë‚˜ëˆˆ ê°’.\n",
      "ì˜ˆì‹œ: ì• í”Œì˜ EPS ì¦ê°€ë¡œ ì¸í•´ ì£¼ê°€ ìƒìŠ¹ ê¸°ëŒ€ê°ì´ ì»¤ì§.\n",
      "ì—°ê´€ í‚¤ì›Œë“œ: ê¸°ì—… ì‹¤ì , íˆ¬ì íŒë‹¨, ì£¼ì‹ ë¶„ì„\n",
      "\n",
      "Interest Rate (ì´ììœ¨)\n",
      "\n",
      "ì •ì˜: ëˆì„ ë¹Œë¦´ ë•Œ ì§€ë¶ˆí•´ì•¼ í•˜ëŠ” ë¹„ìš©ì˜ ë¹„ìœ¨.\n",
      "ì˜ˆì‹œ: ì—°ë°©ì¤€ë¹„ì œë„(Fed)ê°€ ê¸°ì¤€ê¸ˆë¦¬ë¥¼ ì¸ìƒí•˜ë©´ ëŒ€ì¶œ ì´ììœ¨ë„ ìƒìŠ¹í•¨.\n",
      "ì—°ê´€ í‚¤ì›Œë“œ: ì¤‘ì•™ì€í–‰, ì±„ê¶Œ ì‹œì¥, ê²½ì œ ì •ì±…\n",
      "\n",
      "Inflation (ì¸í”Œë ˆì´ì…˜)\n",
      "\n",
      "ì •ì˜: ë¬¼ê°€ê°€ ì „ë°˜ì ìœ¼ë¡œ ì§€ì†í•´ì„œ ìƒìŠ¹í•˜ëŠ” ê²½ì œ í˜„ìƒ.\n",
      "ì˜ˆ...\n",
      "\n",
      "\n",
      "ğŸ” [Query]: Hedge Fund ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜?\n",
      "\n",
      "ğŸ”¹ [Result 1]: Mutual Fund (ë®¤ì¶”ì–¼ í€ë“œ)\n",
      "\n",
      "ì •ì˜: ì—¬ëŸ¬ íˆ¬ììì˜ ìê¸ˆì„ ëª¨ì•„ ë‹¤ì–‘í•œ ìì‚°ì— íˆ¬ìí•˜ëŠ” í€ë“œ.\n",
      "ì˜ˆì‹œ: ë®¤ì¶”ì–¼ í€ë“œëŠ” ë¶„ì‚° íˆ¬ìë¡œ ìœ„í—˜ì„ ì¤„ì´ëŠ” ë° ë„ì›€ì„ ì¤Œ.\n",
      "ì—°ê´€ í‚¤ì›Œë“œ: ê°„ì ‘ íˆ¬ì, í¬íŠ¸í´ë¦¬ì˜¤, í€ë“œ ë§¤ë‹ˆì €\n",
      "\n",
      "Hedge Fund (í—¤ì§€í€ë“œ)\n",
      "\n",
      "ì •ì˜: ê³µê²©ì ì¸ íˆ¬ì ì „ëµì„ ì‚¬ìš©í•˜ì—¬ ë†’ì€ ìˆ˜ìµì„ ì¶”êµ¬í•˜ëŠ” íˆ¬ì í€ë“œ.\n",
      "ì˜ˆì‹œ: í—¤ì§€í€ë“œëŠ” ê³µë§¤ë„, ë ˆë²„ë¦¬ì§€ ë“± ë‹¤ì–‘í•œ ì „ëµì„ í™œìš©í•¨.\n",
      "ì—°ê´€ í‚¤ì›Œë“œ: ê³ ìœ„í—˜ íˆ¬ì, ì ê·¹ì  ìš´ìš©, ë ˆë²„ë¦¬ì§€\n",
      "\n",
      "Asset Allocation (ìì‚° ë°°ë¶„)\n",
      "\n",
      "ì •ì˜: íˆ¬ì í¬íŠ¸í´ë¦¬ì˜¤ì—ì„œ ì£¼ì‹, ì±„ê¶Œ, í˜„ê¸ˆ ...\n",
      "\n",
      "ğŸ”¹ [Result 2]: Federal Reserve (ì—°ë°©ì¤€ë¹„ì œë„, Fed)\n",
      "\n",
      "ì •ì˜: ë¯¸êµ­ì˜ ì¤‘ì•™ì€í–‰ìœ¼ë¡œ, ê¸ˆë¦¬ ì •ì±…ê³¼ í†µí™” ê³µê¸‰ì„ ì¡°ì ˆí•¨.\n",
      "ì˜ˆì‹œ: Fedê°€ ê¸ˆë¦¬ë¥¼ ì¸ìƒí•˜ë©´ ì‹œì¥ ìœ ë™ì„±ì´ ê°ì†Œí•  ìˆ˜ ìˆìŒ.\n",
      "ì—°ê´€ í‚¤ì›Œë“œ: ê¸ˆë¦¬, í†µí™”ì •ì±…, ê²½ì œ ì¡°ì •\n",
      "\n",
      "Bond (ì±„ê¶Œ)\n",
      "\n",
      "ì •ì˜: ì •ë¶€ë‚˜ ê¸°ì—…ì´ ìê¸ˆì„ ì¡°ë‹¬í•˜ê¸° ìœ„í•´ ë°œí–‰í•˜ëŠ” ë¶€ì±„ ì¦ì„œë¡œ, ì¼ì • ê¸°ê°„ ë™ì•ˆ ì´ìë¥¼ ì§€ê¸‰í•˜ê³  ë§Œê¸°ì— ì›ê¸ˆì„ ìƒí™˜í•¨.\n",
      "ì˜ˆì‹œ: ë¯¸êµ­ êµ­ì±„ëŠ” ì•ˆì „í•œ íˆ¬ì ìˆ˜ë‹¨ìœ¼ë¡œ ê°„ì£¼ë¨.\n",
      "ì—°ê´€ í‚¤ì›Œë“œ: ê³ ì • ìˆ˜ìµ, íˆ¬ì, ê¸ˆë¦¬\n",
      "\n",
      "Stock (ì£¼ì‹)\n",
      "\n",
      "ì •ì˜: ê¸°ì—…ì˜ ì§€ë¶„ì„ ë‚˜íƒ€ë‚´ë©°, ì£¼ì‹ì„ ë³´ìœ í•œ íˆ¬ììëŠ” ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import TextLoader  # í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë”\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings  # OpenAI ì„ë² ë”© ì‚¬ìš©\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # í…ìŠ¤íŠ¸ ë¶„í• ê¸°\n",
    "from langchain_chroma import Chroma  # ë²¡í„° DB (Chroma) ì‚¬ìš©\n",
    "\n",
    "\n",
    "# 2. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ê²½ë¡œ ì„¤ì •\n",
    "DB_PATH = \"./db/chroma_db\"\n",
    "\n",
    "# 3. í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë¬¸ì„œë¥¼ ë¶„í• í•˜ëŠ” í•¨ìˆ˜ ì •ì˜\n",
    "def load_and_split_text(file_path, splitter):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë¡œë“œí•œ í›„, ì„¤ì •ëœ Splitterë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ\n",
    "        splitter (RecursiveCharacterTextSplitter): í…ìŠ¤íŠ¸ ë¶„í• ê¸° ê°ì²´\n",
    "\n",
    "    Returns:\n",
    "        list: ë¶„í• ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\" íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        loader = TextLoader(file_path)  # í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ\n",
    "        return loader.load_and_split(splitter)  # ë¶„í• í•˜ì—¬ ë°˜í™˜\n",
    "    except Exception as e:\n",
    "        print(f\" íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({file_path}): {e}\")\n",
    "        return []\n",
    "\n",
    "# 4. í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì • (600ì ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³ , 100ì ê²¹ì¹¨ í¬í•¨)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=100)\n",
    "\n",
    "# 5. ë‘ ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ ë° ë¶„í• \n",
    "split_doc1 = load_and_split_text(\"data/ai-terminology.txt\", text_splitter)\n",
    "split_doc2 = load_and_split_text(\"data/finance-terminology.txt\", text_splitter)\n",
    "\n",
    "# 6. ë¬¸ì„œ ê°œìˆ˜ ì¶œë ¥\n",
    "print(f\"AI ë¬¸ì„œ ê°œìˆ˜: {len(split_doc1)}\")\n",
    "print(f\"ê¸ˆìœµ ë¬¸ì„œ ê°œìˆ˜: {len(split_doc2)}\")\n",
    "\n",
    "# 7. ëª¨ë“  ë¬¸ì„œ í•©ì¹˜ê¸°\n",
    "all_documents = split_doc1 + split_doc2\n",
    "\n",
    "# 8. Chroma ë²¡í„° DB ìƒì„± ë° ì €ì¥\n",
    "try:\n",
    "    persist_db = Chroma.from_documents(\n",
    "        documents=all_documents,\n",
    "        embedding=OpenAIEmbeddings(),  # OpenAI Embeddings ì‚¬ìš©\n",
    "        persist_directory=DB_PATH,  # ë²¡í„° DB ì €ì¥ ìœ„ì¹˜ ì§€ì •\n",
    "        collection_name=\"my_vector_db\",  # ë°ì´í„°ë² ì´ìŠ¤ ì»¬ë ‰ì…˜ ì´ë¦„\n",
    "    )\n",
    "    print(\"Chroma ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ!\")\n",
    "except Exception as e:\n",
    "    print(f\" Chroma ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# 9. ì €ì¥ëœ ë°ì´í„° í™•ì¸\n",
    "try:\n",
    "    retrieved_docs = persist_db.get()  # Chroma DBì—ì„œ ë°ì´í„° ì¡°íšŒ\n",
    "    print(f\" ì €ì¥ëœ ë²¡í„° ê°œìˆ˜: {len(retrieved_docs['ids'])}, íƒ€ì… {type(retrieved_docs['ids'])}\")\n",
    "except Exception as e:\n",
    "    print(f\" ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# 10. ìœ ì‚¬ë„ ê²€ìƒ‰ í•¨ìˆ˜ ì •ì˜\n",
    "def search_query(query, k=2):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì…ë ¥(query)ì— ëŒ€í•´ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜.\n",
    "\n",
    "    Args:\n",
    "        query (str): ê²€ìƒ‰í•  ë¬¸ì¥ (ì˜ˆ: \"Transformer ê°œë… ì„¤ëª…\")\n",
    "        k (int, optional): ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        None: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¶œë ¥\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = persist_db.similarity_search(query, k=k)  # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "        print(f\"\\n [Query]: {query}\\n\")\n",
    "        for i, doc in enumerate(results):\n",
    "            print(f\"ğŸ”¹ [Result {i+1}]: {doc.page_content[:300]}...\\n\")  # ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "    except Exception as e:\n",
    "        print(f\" ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# 11. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "search_query(\"Transformer ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\", k=2)\n",
    "search_query(\"Hedge Fund ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜?\", k=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d910ef",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
