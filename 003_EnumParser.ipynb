{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìˆ˜ì •ëœ LangChain EnumOutputParser ì˜ˆì œ: ê°ì • ë¶„ì„\n",
    "`ChatOpenAI`ì™€ `EnumOutputParser`ë¥¼ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ **ê¸ì •/ë¶€ì •/ì¤‘ë¦½**ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ”§ ì˜¤ë¥˜ í•´ê²° í¬ì¸íŠ¸\n",
    "- ë” ê°•ë ¥í•˜ê³  ëª…í™•í•œ í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "- OutputFixingParser ì¶”ê°€ë¡œ ì•ˆì •ì„± í–¥ìƒ\n",
    "- ì—ëŸ¬ ì²˜ë¦¬ ë¡œì§ í¬í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import EnumOutputParser, OutputFixingParser\n",
    "from langchain.schema import OutputParserException\n",
    "\n",
    "from enum import Enum\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°ì • í´ë˜ìŠ¤ ì •ì˜ (Enum)\n",
    "class Sentiment(str, Enum):\n",
    "    POSITIVE = \"ê¸ì •\"\n",
    "    NEGATIVE = \"ë¶€ì •\"\n",
    "    NEUTRAL = \"ì¤‘ë¦½\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°ì • ë¶„ë¥˜ ì¶œë ¥ í˜•ì‹:\n",
      "Select one of the following options: ê¸ì •, ë¶€ì •, ì¤‘ë¦½\n"
     ]
    }
   ],
   "source": [
    "# EnumOutputParser ì´ˆê¸°í™”\n",
    "parser = EnumOutputParser(enum=Sentiment)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "print(\"ê°ì • ë¶„ë¥˜ ì¶œë ¥ í˜•ì‹:\")\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "template = \"\"\"\n",
    "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³ , ë°˜ë“œì‹œ ì•„ë˜ ì„¸ ê°€ì§€ ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "í…ìŠ¤íŠ¸: \"{text}\"\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "ì¤‘ìš” ê·œì¹™:\n",
    "1. ë°˜ë“œì‹œ \"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\" ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\n",
    "2. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ ì„¤ëª…ì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”\n",
    "3. ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ë¬¸ìë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”\n",
    "4. ì˜¤ì§ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ë° íŒŒì„œ ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ì„¤ì • (ì‹¤ì œ ì‚¬ìš©ì‹œ ì£¼ì„ í•´ì œ)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "# model = ChatOpenAI(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     temperature=0  # ì¼ê´€ì„±ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •\n",
    "# )\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0  # ì¼ê´€ì„±ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •\n",
    ")\n",
    "\n",
    "# OutputFixingParserë¡œ ì•ˆì •ì„± í–¥ìƒ\n",
    "fixing_parser = OutputFixingParser.from_llm(parser=parser, llm=model)\n",
    "\n",
    "print(\"ëª¨ë¸ ë° íŒŒì„œ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸ 6ê°œ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸\n",
    "texts = [\n",
    "    \"ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”! ì™„ì „ ë§Œì¡±ìŠ¤ëŸ¬ì›Œìš”.\",\n",
    "    \"ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ëŠë¦¬ê³  ë¶ˆì¹œì ˆí–ˆìŠµë‹ˆë‹¤.\",\n",
    "    \"ì´ ì œí’ˆ ê·¸ëŸ°ëŒ€ë¡œ ê´œì°®ìŠµë‹ˆë‹¤.\",\n",
    "    \"ë°°ì†¡ì€ ë¹ ë¥´ì§€ë§Œ í’ˆì§ˆì´ ì•„ì‰½ìŠµë‹ˆë‹¤.\",\n",
    "    \"ìµœê³ ì˜ ê²½í—˜ì´ì—ˆìŠµë‹ˆë‹¤!\",\n",
    "    \"ì™„ì „ ì‹¤ë§í–ˆì–´ìš”... ìµœì•…ì´ì—ìš”\"\n",
    "]\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸ {len(texts)}ê°œ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ìˆ˜ë™ í…ŒìŠ¤íŠ¸ (ì‹œë®¬ë ˆì´ì…˜) ===\n",
      " 'ê¸ì •' â†’ ê¸ì • (ì„±ê³µ)\n",
      " 'ë¶€ì •' â†’ ë¶€ì • (ì„±ê³µ)\n",
      " 'ì¤‘ë¦½' â†’ ì¤‘ë¦½ (ì„±ê³µ)\n",
      "\n",
      "ì˜ëª»ëœ í˜•ì‹ í…ŒìŠ¤íŠ¸:\n",
      " 'ë¶„ì„ ê²°ê³¼: ê¸ì •' â†’ íŒŒì‹± ì‹¤íŒ¨ (ì˜ˆìƒë¨)\n",
      " 'ì´ í…ìŠ¤íŠ¸ëŠ” ê¸ì •ì ì…ë‹ˆë‹¤' â†’ íŒŒì‹± ì‹¤íŒ¨ (ì˜ˆìƒë¨)\n",
      " 'positive' â†’ íŒŒì‹± ì‹¤íŒ¨ (ì˜ˆìƒë¨)\n"
     ]
    }
   ],
   "source": [
    "# ìˆ˜ë™ í…ŒìŠ¤íŠ¸ (API í‚¤ ì—†ì´ë„ ì‘ë™)\n",
    "def manual_test():\n",
    "    \"\"\"ìˆ˜ë™ í…ŒìŠ¤íŠ¸ - API í‚¤ ì—†ì´ë„ í™•ì¸ ê°€ëŠ¥\"\"\"\n",
    "    print(\"=== ìˆ˜ë™ í…ŒìŠ¤íŠ¸ (ì‹œë®¬ë ˆì´ì…˜) ===\")\n",
    "    \n",
    "    # ì˜¬ë°”ë¥¸ í˜•ì‹ì˜ ì‘ë‹µë“¤\n",
    "    test_responses = [\"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\"]\n",
    "    \n",
    "    for response in test_responses:\n",
    "        try:\n",
    "            parsed = parser.parse(response)\n",
    "            print(f\" '{response}' â†’ {parsed.value} (ì„±ê³µ)\")\n",
    "        except Exception as e:\n",
    "            print(f\" '{response}' â†’ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ì˜ëª»ëœ í˜•ì‹ì˜ ì‘ë‹µë“¤\n",
    "    wrong_responses = [\n",
    "        \"ë¶„ì„ ê²°ê³¼: ê¸ì •\",\n",
    "        \"ì´ í…ìŠ¤íŠ¸ëŠ” ê¸ì •ì ì…ë‹ˆë‹¤\",\n",
    "        \"positive\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nì˜ëª»ëœ í˜•ì‹ í…ŒìŠ¤íŠ¸:\")\n",
    "    for response in wrong_responses:\n",
    "        try:\n",
    "            parsed = parser.parse(response)\n",
    "            print(f\" '{response}' â†’ {parsed.value} (ì˜ˆìƒì™¸ ì„±ê³µ)\")\n",
    "        except Exception as e:\n",
    "            print(f\" '{response}' â†’ íŒŒì‹± ì‹¤íŒ¨ (ì˜ˆìƒë¨)\")\n",
    "\n",
    "# ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "manual_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì‹¤ì œ ê°ì • ë¶„ì„ ê²°ê³¼ ===\n",
      "\n",
      "1. í…ìŠ¤íŠ¸: ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”! ì™„ì „ ë§Œì¡±ìŠ¤ëŸ¬ì›Œìš”.\n",
      "   ê°ì •: ê¸ì • \n",
      "\n",
      "2. í…ìŠ¤íŠ¸: ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ëŠë¦¬ê³  ë¶ˆì¹œì ˆí–ˆìŠµë‹ˆë‹¤.\n",
      "   ê°ì •: ë¶€ì • \n",
      "\n",
      "3. í…ìŠ¤íŠ¸: ì´ ì œí’ˆ ê·¸ëŸ°ëŒ€ë¡œ ê´œì°®ìŠµë‹ˆë‹¤.\n",
      "   ê°ì •: ì¤‘ë¦½ \n",
      "\n",
      "4. í…ìŠ¤íŠ¸: ë°°ì†¡ì€ ë¹ ë¥´ì§€ë§Œ í’ˆì§ˆì´ ì•„ì‰½ìŠµë‹ˆë‹¤.\n",
      "   ê°ì •: ë¶€ì • \n",
      "\n",
      "5. í…ìŠ¤íŠ¸: ìµœê³ ì˜ ê²½í—˜ì´ì—ˆìŠµë‹ˆë‹¤!\n",
      "   ê°ì •: ê¸ì • \n",
      "\n",
      "6. í…ìŠ¤íŠ¸: ì™„ì „ ì‹¤ë§í–ˆì–´ìš”... ìµœì•…ì´ì—ìš”\n",
      "   ê°ì •: ë¶€ì • \n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "ì„±ê³µ: 6/6 (100.0%)\n",
      "ì‹¤íŒ¨: 0/6\n"
     ]
    }
   ],
   "source": [
    "# ì•ˆì „í•œ ê°ì • ë¶„ì„ í•¨ìˆ˜ (ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)\n",
    "def safe_sentiment_analysis(text, use_fixing_parser=True):\n",
    "    \"\"\"ì•ˆì „í•œ ê°ì • ë¶„ì„ í•¨ìˆ˜ - ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨\"\"\"\n",
    "    try:\n",
    "        # ê¸°ë³¸ ì²´ì¸ ìƒì„±\n",
    "        chain = prompt | model | (fixing_parser if use_fixing_parser else parser)\n",
    "        \n",
    "        # ë¶„ì„ ì‹¤í–‰\n",
    "        result = chain.invoke({\"text\": text})\n",
    "        return result, None\n",
    "        \n",
    "    except OutputParserException as e:\n",
    "        return None, f\"íŒŒì‹± ì˜¤ë¥˜: {str(e)[:100]}...\"\n",
    "    except Exception as e:\n",
    "        return None, f\"ì¼ë°˜ ì˜¤ë¥˜: {str(e)[:100]}...\"\n",
    "\n",
    "# ì‹¤ì œ ê°ì • ë¶„ì„ ì‹¤í–‰ (API í‚¤ í•„ìš”)\n",
    "def run_sentiment_analysis():\n",
    "    \"\"\"ì‹¤ì œ ê°ì • ë¶„ì„ ì‹¤í–‰\"\"\"\n",
    "    print(\"=== ì‹¤ì œ ê°ì • ë¶„ì„ ê²°ê³¼ ===\")\n",
    "    \n",
    "    success_count = 0\n",
    "    total_count = len(texts)\n",
    "    \n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f\"\\n{i}. í…ìŠ¤íŠ¸: {text}\")\n",
    "        \n",
    "        # OutputFixingParser ì‚¬ìš©\n",
    "        result, error = safe_sentiment_analysis(text, use_fixing_parser=True)\n",
    "        \n",
    "        if result:\n",
    "            print(f\"   ê°ì •: {result.value} \")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"   ì˜¤ë¥˜: {error} \")\n",
    "            \n",
    "            # ê¸°ë³¸ íŒŒì„œë¡œ ì¬ì‹œë„\n",
    "            print(\"   ê¸°ë³¸ íŒŒì„œë¡œ ì¬ì‹œë„...\")\n",
    "            result2, error2 = safe_sentiment_analysis(text, use_fixing_parser=False)\n",
    "            \n",
    "            if result2:\n",
    "                print(f\"   ê°ì •: {result2.value} (ê¸°ë³¸ íŒŒì„œ ì„±ê³µ)\")\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"   ì¬ì‹œë„ ì‹¤íŒ¨: {error2} \")\n",
    "    \n",
    "    print(f\"\\n=== ê²°ê³¼ ìš”ì•½ ===\")\n",
    "    print(f\"ì„±ê³µ: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)\")\n",
    "    print(f\"ì‹¤íŒ¨: {total_count-success_count}/{total_count}\")\n",
    "\n",
    "# ì‹¤ì œ ë¶„ì„ ì‹¤í–‰ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)\n",
    "try:\n",
    "    run_sentiment_analysis()\n",
    "except Exception as e:\n",
    "    print(\"API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜:\")\n",
    "    print(\"ì‹¤ì œ ì‹¤í–‰ì„ ìœ„í•´ì„œëŠ” OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "    print(f\"ì˜¤ë¥˜ ìƒì„¸: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ë°°ì¹˜ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ===\n",
      "\n",
      "=== ê°ì • ë¶„ì„ í†µê³„ ===\n",
      "ê¸ì •: 2ê°œ (33.3%)\n",
      "ë¶€ì •: 2ê°œ (33.3%)\n",
      "ì¤‘ë¦½: 1ê°œ (16.7%)\n",
      "ì˜¤ë¥˜: 1ê°œ (16.7%)\n",
      "\n",
      "=== ìƒì„¸ ê²°ê³¼ ===\n",
      "1. ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”! ì™„ì „ ë§Œì¡±ìŠ¤ëŸ¬ì›Œìš”.... â†’ ê¸ì •\n",
      "2. ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ëŠë¦¬ê³  ë¶ˆì¹œì ˆí–ˆìŠµë‹ˆë‹¤.... â†’ ë¶€ì •\n",
      "3. ì˜¤ëŠ˜ì€ ë¹„ê°€ ì˜¨ë‹¤ë„¤ìš”.... â†’ ì¤‘ë¦½\n",
      "4. ë°°ì†¡ì€ ë¹ ë¥´ì§€ë§Œ í’ˆì§ˆì´ ì•„ì‰½ìŠµë‹ˆë‹¤.... â†’ ë¶€ì •\n",
      "5. ìµœê³ ì˜ ê²½í—˜ì´ì—ˆìŠµë‹ˆë‹¤!... â†’ ê¸ì •\n",
      "6. ì™„ì „ ì‹¤ë§í–ˆì–´ìš”... ìµœì•…ì´ì—ìš”... â†’  ì˜¤ë¥˜\n"
     ]
    }
   ],
   "source": [
    "# ì¶”ê°€ ê¸°ëŠ¥: ë°°ì¹˜ ì²˜ë¦¬ ë° í†µê³„\n",
    "def batch_sentiment_analysis(text_list):\n",
    "    \"\"\"ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ê³  í†µê³„ ì œê³µ\"\"\"\n",
    "    results = {\n",
    "        'ê¸ì •': 0,\n",
    "        'ë¶€ì •': 0,\n",
    "        'ì¤‘ë¦½': 0,\n",
    "        'ì˜¤ë¥˜': 0\n",
    "    }\n",
    "    \n",
    "    detailed_results = []\n",
    "    \n",
    "    for text in text_list:\n",
    "        result, error = safe_sentiment_analysis(text)\n",
    "        \n",
    "        if result:\n",
    "            sentiment = result.value\n",
    "            results[sentiment] += 1\n",
    "            detailed_results.append((text, sentiment, None))\n",
    "        else:\n",
    "            results['ì˜¤ë¥˜'] += 1\n",
    "            detailed_results.append((text, None, error))\n",
    "    \n",
    "    return results, detailed_results\n",
    "\n",
    "# í†µê³„ ì¶œë ¥ í•¨ìˆ˜\n",
    "def print_statistics(results, detailed_results):\n",
    "    \"\"\"ê²°ê³¼ í†µê³„ ì¶œë ¥\"\"\"\n",
    "    print(\"\\n=== ê°ì • ë¶„ì„ í†µê³„ ===\")\n",
    "    total = sum(results.values())\n",
    "    \n",
    "    for sentiment, count in results.items():\n",
    "        percentage = (count / total * 100) if total > 0 else 0\n",
    "        print(f\"{sentiment}: {count}ê°œ ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n=== ìƒì„¸ ê²°ê³¼ ===\")\n",
    "    for i, (text, sentiment, error) in enumerate(detailed_results, 1):\n",
    "        status = sentiment if sentiment else \" ì˜¤ë¥˜\"\n",
    "        print(f\"{i}. {text[:30]}... â†’ {status}\")\n",
    "\n",
    "# ë°°ì¹˜ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜\n",
    "print(\"\\n=== ë°°ì¹˜ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ===\")\n",
    "simulated_results = {\n",
    "    'ê¸ì •': 2,\n",
    "    'ë¶€ì •': 2, \n",
    "    'ì¤‘ë¦½': 1,\n",
    "    'ì˜¤ë¥˜': 1\n",
    "}\n",
    "\n",
    "simulated_detailed = [\n",
    "    (texts[0], 'ê¸ì •', None),\n",
    "    (texts[1], 'ë¶€ì •', None),\n",
    "    (texts[2], 'ì¤‘ë¦½', None),\n",
    "    (texts[3], 'ë¶€ì •', None),\n",
    "    (texts[4], 'ê¸ì •', None),\n",
    "    (texts[5], None, \"íŒŒì‹± ì˜¤ë¥˜\")\n",
    "]\n",
    "\n",
    "print_statistics(simulated_results, simulated_detailed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ ì£¼ìš” ìˆ˜ì •ì‚¬í•­\n",
    "\n",
    "### 1. **í”„ë¡¬í”„íŠ¸ ê°œì„ **\n",
    "```python\n",
    "# ê¸°ì¡´ (ë¬¸ì œ)\n",
    "\"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# ìˆ˜ì • (í•´ê²°)\n",
    "\"ë°˜ë“œì‹œ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\"\n",
    "```\n",
    "\n",
    "### 2. **OutputFixingParser ì¶”ê°€**\n",
    "- ê¸°ë³¸ íŒŒì„œê°€ ì‹¤íŒ¨í•˜ë©´ ìë™ìœ¼ë¡œ ì‘ë‹µì„ ìˆ˜ì •í•˜ì—¬ ì¬ì‹œë„\n",
    "- ì•ˆì •ì„± í¬ê²Œ í–¥ìƒ\n",
    "\n",
    "### 3. **ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”**\n",
    "- `safe_sentiment_analysis()` í•¨ìˆ˜ë¡œ ì•ˆì „í•œ ì²˜ë¦¬\n",
    "- ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ ë°©ë²• ì œê³µ\n",
    "\n",
    "### 4. **Temperature ì¡°ì •**\n",
    "- `temperature=0`ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¼ê´€ëœ ì‘ë‹µ ìœ ë„\n",
    "\n",
    "## ğŸ’¡ ì‚¬ìš© íŒ\n",
    "\n",
    "1. **API í‚¤ ì„¤ì •**: ì‹¤ì œ ì‹¤í–‰ì„ ìœ„í•´ì„œëŠ” OpenAI API í‚¤ í•„ìš”\n",
    "2. **ëª¨ë¸ ì„ íƒ**: `gpt-3.5-turbo`ë¡œë„ ì¶©ë¶„í•œ ì„±ëŠ¥\n",
    "3. **í”„ë¡¬í”„íŠ¸ ìµœì í™”**: ë” ëª…í™•í•˜ê³  ê°•ë ¥í•œ ì§€ì‹œì‚¬í•­ í¬í•¨\n",
    "4. **ì•ˆì „ ì¥ì¹˜**: OutputFixingParserë¡œ ì•ˆì •ì„± í™•ë³´"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
