{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "#### LangSmith 기본 예제\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "##### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "##### 2) OpenAI 인증키 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "##### LangSmith와 LangChain을 활용한 기본 로깅 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 [AI 답변]:\n",
      "LangGraph와 LangChain은 모두 텍스트 분석 및 자연어 처리를 위한 도구 중 하나입니다. LangGraph는 다양한 언어 간의 관계를 그래프 형태로 표현하고 분석하는 도구입니다. 반면에 LangChain은 언어 간의 관계를 연쇄적으로 파악하고 해석하는 도구입니다.\n",
      "\n",
      "LangGraph는 언어 간의 유사성 및 상호작용을 시각적으로 파악할 수 있는 그래프를 제공하며, 언어 간의 관련성을 깊이 있게 분석할 수 있도록 도와줍니다. 반면에 LangChain은 특정 언어의 구조를 분석하고 다른 언어에 적용함으로써, 언어 간의 파악된 관계를 연쇄적으로 전이시키는 능력을 강조합니다.\n",
      "\n",
      "따라서 LangGraph는 언어 간의 관계를 그래프로 시각화하여 분석하는데 중점을 두며, LangChain은 언어 간의 관계를 연쇄적인 과정으로 이해하고 해석하는 데 중점을 둡니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langsmith import traceable\n",
    "\n",
    "# LangSmith API Key 설정\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\")  # LangSmith 활성화\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")  # API Key 불러오기\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\")   # 프로젝트 이름 설정\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\")   # EndPoint 설정\n",
    "\n",
    "# LLM 모델 설정 (OpenAI 사용)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# LangSmith로 실행 추적\n",
    "@traceable(run_type=\"chain\", name=\"Simple_Chain\")\n",
    "def ask_question(question: str):\n",
    "\n",
    "    # 개별 메시지 템플릿 정의\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\n",
    "        \"당신은 유용한 AI 비서입니다.\"\n",
    "    )\n",
    "    user_message = HumanMessagePromptTemplate.from_template(\n",
    "        \"{question}\"\n",
    "    )\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        system_message,\n",
    "        user_message,\n",
    "    ])\n",
    "    \n",
    "    messages = chat_prompt.format_messages(question=question)\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return response.content\n",
    "\n",
    "# 테스트 실행\n",
    "question = \"LangGraph와 LangChain의 차이점은 무엇인가요?\"\n",
    "answer = ask_question(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n🔹 [AI 답변]:\")\n",
    "print(answer)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
