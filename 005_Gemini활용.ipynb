{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0fa4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.31.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8264ea0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93f00ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google Gemini Response:\n",
      "LangChain은 대규모 언어 모델(LLM)을 애플리케이션에 통합하기 위한 프레임워크입니다.  단순히 LLM을 호출하는 것 이상으로,  다양한 기능을 제공하여 LLM 기반 애플리케이션 개발을 더욱 효율적이고 강력하게 만들어줍니다.  핵심 기능은 다음과 같습니다.\n",
      "\n",
      "* **모듈화:** LangChain은 LLM, 프로세스, 메모리 등을 모듈화하여 재사용성과 유지보수성을 높입니다.  다양한 LLM(OpenAI, Hugging Face 등)과 데이터 소스를 쉽게 연결하고 교체할 수 있습니다.\n",
      "\n",
      "* **체인(Chains):** 여러 LLM 호출이나 다른 구성 요소를 순차적으로 또는 병렬적으로 연결하여 복잡한 작업을 수행할 수 있습니다.  예를 들어, 문서 요약, 질문 답변, 챗봇 등을 구현할 수 있습니다.  다양한 체인 유형(예: `SequentialChain`, `SimpleSequentialChain`, `LLMChain`)이 제공됩니다.\n",
      "\n",
      "* **인덱싱 및 검색:**  외부 데이터 소스(문서, 데이터베이스 등)를 인덱싱하고 검색하여 LLM이 필요한 정보에 접근할 수 있도록 합니다.  이를 통해 LLM의 지식 범위를 확장하고, 최신 정보를 활용한 응답을 생성할 수 있습니다.  VectorDB와 같은 벡터 데이터베이스를 활용하여 유사도 검색을 수행합니다.\n",
      "\n",
      "* **메모리:**  대화형 애플리케이션에서 이전 대화 내용을 기억하고 활용하여 맥락을 유지할 수 있도록 합니다.  다양한 메모리 유형(예: `ConversationBufferMemory`, `ConversationSummaryMemory`)이 제공됩니다.\n",
      "\n",
      "* **에이전트(Agents):**  LLM이 외부 도구(검색 엔진, 계산기 등)를 호출하여 작업을 수행할 수 있도록 합니다.  에이전트는 LLM이 어떤 도구를 사용할지 결정하고, 그 결과를 활용하여 최종 응답을 생성합니다.\n",
      "\n",
      "* **다양한 LLM 및 데이터 소스 지원:** OpenAI, Hugging Face Hub,  자체적으로 구축한 LLM 등 다양한 LLM을 지원하며,  CSV, JSON, 웹 페이지 등 다양한 데이터 소스를 처리할 수 있습니다.\n",
      "\n",
      "\n",
      "**LangChain의 장점:**\n",
      "\n",
      "* **개발 속도 향상:**  모듈화된 구성 요소와 다양한 기능을 통해 LLM 기반 애플리케이션 개발 시간을 단축할 수 있습니다.\n",
      "* **유지보수 용이성:**  모듈화된 설계로 코드의 유지보수 및 확장이 용이합니다.\n",
      "* **재사용성:**  구성 요소를 재사용하여 다양한 애플리케이션을 개발할 수 있습니다.\n",
      "* **확장성:**  새로운 LLM이나 데이터 소스를 쉽게 통합할 수 있습니다.\n",
      "\n",
      "\n",
      "**LangChain의 단점:**\n",
      "\n",
      "* **복잡성:**  다양한 기능과 구성 요소로 인해 초보자에게는 다소 복잡하게 느껴질 수 있습니다.\n",
      "* **학습 곡선:**  LangChain을 효과적으로 사용하기 위해서는 일정 수준의 학습이 필요합니다.\n",
      "\n",
      "\n",
      "결론적으로, LangChain은 LLM 기반 애플리케이션 개발을 위한 강력하고 유연한 프레임워크입니다.  복잡한 애플리케이션을 구축하려는 개발자에게는 매우 유용한 도구이지만,  간단한 LLM 애플리케이션을 개발하는 경우에는 오히려 불필요한 복잡성을 추가할 수 있습니다.  프로젝트의 규모와 복잡성을 고려하여 LangChain을 사용할지 여부를 결정하는 것이 중요합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "    \n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",  # 또는 \"gemini-pro-vision\"\n",
    "    temperature=0.3    \n",
    ")\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 AI 전문가입니다다.\"),\n",
    "    (\"human\", \"{topic}은 무엇인가요?\")\n",
    "])\n",
    "\n",
    "# 체인 실행\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"topic\": \"LangChain\"})\n",
    "\n",
    "print(\" Google Gemini Response:\")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
