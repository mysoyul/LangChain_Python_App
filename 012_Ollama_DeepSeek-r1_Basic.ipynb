{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain\n",
    "%pip install -q langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로컬 Ollama로 설치한 deepseek-r1:1.5b 모델을 사용하기\n",
    "##### ollama run deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'question': 'What is LangChain?', 'text': '<think>\\n\\n</think>\\n\\nLangChain is a technology that combines language models with real-time data from the web, social media, and other sources to generate human-like text. It simplifies content creation by allowing users to create datasets automatically or manually in response to specific prompts, reducing manual work and time investment.\\n\\nHere are some key features of LangChain:\\n\\n1. **Automated Dataset Generation**: Users can easily collect data by asking questions like \"What are your favorite restaurants?\" with prompting functions.\\n\\n2. **Real-Time Data Integration**: LangChain integrates real-time data from websites, social media platforms, and other sources to provide up-to-date content.\\n\\n3. **Prompting and Feedback**: Users can craft prompts or use pre-built templates to guide the language model through their thinking process.\\n\\n4. **Simplified Content Creation**: It reduces the time and effort required to create engaging content by automating dataset generation.\\n\\n5. **Customizable Models**: Users can choose from a variety of language models, tailoring the output to their needs.\\n\\nLangChain is used in various fields like marketing, education, customer service, and entertainment to produce high-quality, relevant text quickly.'}\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "LangChain is a technology that combines language models with real-time data from the web, social media, and other sources to generate human-like text. It simplifies content creation by allowing users to create datasets automatically or manually in response to specific prompts, reducing manual work and time investment.\n",
      "\n",
      "Here are some key features of LangChain:\n",
      "\n",
      "1. **Automated Dataset Generation**: Users can easily collect data by asking questions like \"What are your favorite restaurants?\" with prompting functions.\n",
      "\n",
      "2. **Real-Time Data Integration**: LangChain integrates real-time data from websites, social media platforms, and other sources to provide up-to-date content.\n",
      "\n",
      "3. **Prompting and Feedback**: Users can craft prompts or use pre-built templates to guide the language model through their thinking process.\n",
      "\n",
      "4. **Simplified Content Creation**: It reduces the time and effort required to create engaging content by automating dataset generation.\n",
      "\n",
      "5. **Customizable Models**: Users can choose from a variety of language models, tailoring the output to their needs.\n",
      "\n",
      "LangChain is used in various fields like marketing, education, customer service, and entertainment to produce high-quality, relevant text quickly.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 deepseek-r1 모델을 로드\n",
    "llm = Ollama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Q: {question}\\nA:\"\n",
    ")\n",
    "\n",
    "# LLMChain 생성\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# 질문을 입력하고 모델의 응답을 받음\n",
    "question = \"What is LangChain?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "# 결과 출력\n",
    "print(type(response))\n",
    "print(response)\n",
    "print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 최신버전 LangChain에서는 ChatOllama와 RunnableSequence(prompt | llm) 를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='<think>\\nOkay, the user asked, \"What is LangChain?\" I remember they\\'ve been talking about AI models in their previous questions. LangChain seems to be related.\\n\\nI think it\\'s a tool for generating text with specific requirements. Maybe it uses an underlying model like LLaMA or Llama B? I should explain that briefly and then mention how you can use it, maybe through the LangChain API.\\n\\nThey might want to know when to use it versus other text generation methods. Also, perhaps they\\'re interested in how to set up their models with LangChain.\\n\\nI\\'ll make sure to keep it clear and provide some code snippets so they can see practical examples.\\n</think>\\n\\nLangChain is a Python library designed for generating human-like text using advanced AI models. It allows you to use large language models (LLMs) like LLaMA, Llama B, or others directly within your Python code.\\n\\nHere\\'s an example of how you can use LangChain:\\n\\n```python\\n# First, install the LangChain package and its dependencies.\\n!pip install langchain\\n\\n# Import the TextGenerator class from LangChain.\\nfrom langchain.textgenerate import TextGenerator\\n\\n# Create a default model (like Llama B) using AutoModelForCausalInferenceLmCross.\\ngenerator = TextGenerator(\\n    model=\"google/mamesa/llama2\",\\n    n_ctx=384,\\n    n_threads=1\\n)\\n\\n# Generate some text based on the prompt.\\nprompt = \"The Great Gatsby is a famous novel by F. Scott Fitzgerald...\"\\ngenerated_text = generator.generate(\\n    model=None,\\n    prompt=prompt,\\n    temperature=0.7,\\n    top_k=500,\\n    max_tokens=2000\\n)\\n\\nprint(generated_text)\\n```\\n\\nLangChain offers flexibility in how you can generate text, including customization of the model configuration and parameters to match your needs.' additional_kwargs={} response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-03-05T09:07:07.3033924Z', 'done': True, 'done_reason': 'stop', 'total_duration': 19459765000, 'load_duration': 20788800, 'prompt_eval_count': 24, 'prompt_eval_duration': 58000000, 'eval_count': 389, 'eval_duration': 19379000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-507c730e-dfb7-4127-8c30-62a345a315aa-0' usage_metadata={'input_tokens': 24, 'output_tokens': 389, 'total_tokens': 413}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "#from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 llama3.2 모델 로드\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "# prompt_template = PromptTemplate.from_template(\"Q: {question}\\nA:\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"What is LangChain?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user asked, \"What is LangChain?\" I remember they've been talking about AI models in their previous questions. LangChain seems to be related.\n",
      "\n",
      "I think it's a tool for generating text with specific requirements. Maybe it uses an underlying model like LLaMA or Llama B? I should explain that briefly and then mention how you can use it, maybe through the LangChain API.\n",
      "\n",
      "They might want to know when to use it versus other text generation methods. Also, perhaps they're interested in how to set up their models with LangChain.\n",
      "\n",
      "I'll make sure to keep it clear and provide some code snippets so they can see practical examples.\n",
      "</think>\n",
      "\n",
      "LangChain is a Python library designed for generating human-like text using advanced AI models. It allows you to use large language models (LLMs) like LLaMA, Llama B, or others directly within your Python code.\n",
      "\n",
      "Here's an example of how you can use LangChain:\n",
      "\n",
      "```python\n",
      "# First, install the LangChain package and its dependencies.\n",
      "!pip install langchain\n",
      "\n",
      "# Import the TextGenerator class from LangChain.\n",
      "from langchain.textgenerate import TextGenerator\n",
      "\n",
      "# Create a default model (like Llama B) using AutoModelForCausalInferenceLmCross.\n",
      "generator = TextGenerator(\n",
      "    model=\"google/mamesa/llama2\",\n",
      "    n_ctx=384,\n",
      "    n_threads=1\n",
      ")\n",
      "\n",
      "# Generate some text based on the prompt.\n",
      "prompt = \"The Great Gatsby is a famous novel by F. Scott Fitzgerald...\"\n",
      "generated_text = generator.generate(\n",
      "    model=None,\n",
      "    prompt=prompt,\n",
      "    temperature=0.7,\n",
      "    top_k=500,\n",
      "    max_tokens=2000\n",
      ")\n",
      "\n",
      "print(generated_text)\n",
      "```\n",
      "\n",
      "LangChain offers flexibility in how you can generate text, including customization of the model configuration and parameters to match your needs.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
