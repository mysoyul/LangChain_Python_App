1️⃣ Transformer 모델
정의:
Transformer는 자연어 처리(NLP)에서 널리 사용되는 딥러닝 모델로, 자기 주의(Self-Attention) 메커니즘을 활용하여 문맥을 효과적으로 이해합니다.

특징:

RNN보다 병렬 연산이 가능하여 훈련 속도가 빠름
입력 문장의 단어 순서와 관계를 잘 유지함
GPT, BERT, T5 같은 최신 NLP 모델의 기반이 됨
예시:
GPT 모델과 BERT 모델은 Transformer 아키텍처를 기반으로 동작합니다.

연관 키워드:
딥러닝, 자연어 처리, Attention, GPT, BERT

2️⃣ 벡터 데이터베이스 (Vector Database)
정의:
벡터 데이터베이스는 문서, 이미지, 텍스트 등의 데이터를 벡터로 변환하여 저장하고 유사한 데이터를 검색할 수 있도록 설계된 데이터베이스입니다.

특징:

데이터 간 유사도를 기반으로 검색 가능 (예: similarity_search())
대규모 데이터에서도 빠른 검색 성능 제공
FAISS, Chroma, Pinecone, Weaviate 등 다양한 오픈소스 라이브러리 존재
예시:
FAISS는 Facebook AI가 개발한 벡터 검색 라이브러리로, 수백만 개의 문서에서 유사한 결과를 빠르게 찾을 수 있습니다.

연관 키워드:
임베딩, 유사도 검색, Chroma, FAISS, 벡터화